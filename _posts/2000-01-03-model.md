---
title: "Model"
bg: #9AD1F5
color: black
style: center
fa-icon: project-diagram
---

<p style='text-align: justify;'>

In this work it has been proposed a novel method - progressive augmentation (PA) - to improve the stability of GAN training, and showed a way to integrate it into existing GAN architectures with minimal changes.
<br />
The discriminator learning faster than then generator leads to GAN instability. Hence, PA focuses on making harder the learning task of the discriminator by augmenting progressively its input space with an arbitrary long random bit sequence s.
<br />
The class of the augmented sample (x,s) is then set based on the combination x with s (XOR function), resulting in real and generated samples contained in both true and fake classes, thus, making the learning task more challenging as it can be seen in the next figure.
<br />
<img src="./assets/pa.png" alt="PA-training"/>
<br />
Also, in the following figure, it is shown the architecture that is was used for this project, based on the generator and the discriminator of the SN-DCGAN and the progressive augmentation module in between.
<br />
<img src="./assets/im1.png" alt="SN-DCGAN Model"/>
<img src="./assets/im2.png" alt="SN-DCGAN Model"/>
<br />
The specifications of the GAN network are shown in tables a) and b).

<br />

</p>

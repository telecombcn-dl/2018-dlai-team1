---
title: "Approach"
bg: blue
color: white
style: center
fa-icon: terminal
---

<p style='text-align: justify;'>

In this section we intent to explain in detail the work that we have been doing in order to achieve the main goal, which was to reproduce the paper.
<br />
The first thing we did was to study the paper individually for a one week period time. In that way, we would be able to share the main concepts and doubts in the first scheduled meeting.
<br />
Once we thought we have understood the paper, we started working towards a baseline. Thus, we wanted to implement it in order to be able to compare our results in the future. The baseline was a SN-DCGAN  (spectral normalized deep convolutional general adversarial network ), and after researching, we found a <a href="https://github.com/minhnhat93/tf-SNDCGAN">github repository</a> which implemented a simple DCGAN (we were still missing the SN part). This model was implemented in Tensorflow.
<br />
In order to add the SN to the baseline, we used a part of the code of an already implemented SN-GAN <a href="https://github.com/taki0112/Spectral_Normalization-Tensorflow">github repository</a>, which followed the following algorithm.
<br />
<br />
The metrics that were used in the paper to evaluate the performance of the system were mainly two: KID () and FID (). It was also necessary to implement them. Here is were the problems started: Miki had a job interview.
<br />
We found a <a href="https://github.com/google/compare_gan/tree/master/compare_gan/src">code</a> that allowed us to implement the KID. However, it was really difficulty to adapt it with our code and we decided to implement it ourself by just using pre-trained Keras inception network and writing the algorithm by numpy library.
<br />
At the same time, we were implementing progressive augmentation (PA), the key point of the whole paper. This lead to some difficulties when trying to modify the model when adding a channel to the input space and first convolutional layer of the discriminator. This was because Tensorflow uses a static graph and so it makes it very hard to modify the system during runtime. At this point, we decided to change our framework to Pytorch, which uses a dynamic graph.
<br />
At that stage we looked for a new DCGAN, now in Pytorch. However, we could not find the same one as in the paper and so we decided to implement it based on this <a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">pytorch example</a>. It turned out that Spectral Normalization was already implemented in the latest version of Pytorch. Thus, we just had built our baseline!
<br />
<br />
Then, we needed to have the KID and the FID metrics also in Pytorch. We adapted this <a href="https://github.com/mseitzer/pytorch-fid">repository</a> for the FID and implemented the KID ourself, by using Pytorch's inception.
<br />
<br />
Once having all implemented in Pytorch, it was easier to implement PA, and we did so.
<br />
</p>

<!-- <img src="./assets/algorithm.jpeg" alt="Spectral normalization"/> -->

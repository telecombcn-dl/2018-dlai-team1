---
title: R.Challenge
bg: blue
color: white
fa-icon: quote-left
---
<p style='text-align: justify;'>

One of the challenges in machine learning research is to ensure that published results are reliable and reproducible. In support of this, this <a href="https://github.com/reproducibility-challenge/iclr_2019">challenge</a> have been set up in order to investigate the reproducibility of empirical results submitted to the 2019 International Conference on Learning Representations (ICLR).
<br>
<br>
The paper that we chose can be found <a href="https://openreview.net/pdf?id=ByeNFoRcK7">here</a> and its abstract is showed below:
<br>
<strong> <center> PA-GAN: IMPROVING GAN TRAINING BY PROGRESSIVE AUGMENTATION </center> </strong>
<br>
Despite recent progress, Generative Adversarial Networks (GANs) still suffer from training instability, requiring careful consideration of architecture design choices and hyper-parameter tuning. The reason for this fragile training behaviour is partially due to the discriminator performing well very quickly; its loss converges to zero, providing no reliable backpropagation signal to the generator. In this work we introduce a new technique - progressive augmentation of GANs (PAGAN) - that helps to overcome this fundamental limitation and improve the overall stability of GAN training. The key idea is to gradually increase the task difficulty of the discriminator by progressively augmenting its input space, thus enabling continuous learning of the generator. We show that the proposed progressive augmentation preserves the original GAN objective, does not bias the optimality of the discriminator and encourages the healthy competition between the generator and discriminator, leading to a better-performing generator. We experimentally demonstrate the effectiveness of the proposed approach on multiple benchmarks (MNIST, Fashion-MNIST, CIFAR10, CELEBA) for the image generation task.
</p>
